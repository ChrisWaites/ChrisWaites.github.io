(this["webpackJsonppersonal-site"]=this["webpackJsonppersonal-site"]||[]).push([[0],{13:function(e,t,a){},28:function(e,t,a){e.exports=a(41)},29:function(e,t,a){},41:function(e,t,a){"use strict";a.r(t);a(29),Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));a(13);var n=a(0),i=a.n(n),l=a(23),r=a(10);var o=function(e){return i.a.createElement("div",{style:{display:"flex",alignItems:"flex-start",justifyContent:"center"}},i.a.createElement("div",{style:{padding:"60px",width:"40%",textAlign:"left"}},e.children),i.a.createElement(l.a,{style:{paddingTop:"60px",textAlign:"right"}},i.a.createElement("table",null,i.a.createElement("tr",null,i.a.createElement("td",null,i.a.createElement("strong",null,i.a.createElement(r.b,{className:"link",to:"/"},"Chris Waites")))),i.a.createElement("tr",null,i.a.createElement("td",null,i.a.createElement(r.b,{className:"link",to:"/research"},"Research"))),i.a.createElement("tr",null,i.a.createElement("td",null,i.a.createElement(r.b,{className:"link",to:"/writing"},"Writing"))),i.a.createElement("tr",null,i.a.createElement("td",null,i.a.createElement(r.b,{className:"link",to:"/reading"},"Reading"))),i.a.createElement("tr",null,i.a.createElement("td",null,i.a.createElement(r.b,{className:"link",to:"/design"},"Design"))),i.a.createElement("tr",null,i.a.createElement("td",null,i.a.createElement("a",{href:"https://github.com/ChrisWaites"},"Github"))))))},s=a(3),h=a(54);function c(e){return i.a.createElement("p",null,i.a.createElement(h.a,{variant:"outlined",href:e.href},e.children))}var m=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement(c,{href:"https://invertibleworkshop.github.io/accepted_papers/pdfs/41.pdf"},i.a.createElement("em",null,"Differentially Private Normalizing Flows for Privacy-Preserving Density Estimation"),i.a.createElement("br",null),i.a.createElement("hr",null),"Chris Waites and Rachel Cummings.",i.a.createElement("br",null),i.a.createElement("em",null,"ICML Workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models.")),i.a.createElement(c,{href:"https://arxiv.org/abs/1912.03250"},i.a.createElement("em",null,"Differentially Private Mixed-Type Data Generation For Unsupervised Learning"),i.a.createElement("br",null),i.a.createElement("hr",null),"Uthaipon Tantipongpipat*, Chris Waites*, Digvijay Boob, Amaresh Ankit Siva, and Rachel Cummings.",i.a.createElement("br",null),i.a.createElement("em",null,"arXiv:1912.03250.")))};var u=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("p",null,i.a.createElement("img",{src:"./academic-banner.jpeg",style:{borderRadius:"10px",width:"100%"}})),i.a.createElement("p",null,"Hi! I","'","m Chris."),i.a.createElement("p",null,"Currently, I","'","m doing my M.S. in Computer Science at ",i.a.createElement("a",{href:"https://www.stanford.edu/"},"Stanford University"),". Previously, I did my B.S. in Computer Science at the ",i.a.createElement("a",{href:"https://www.gatech.edu/"},"Georgia Institute of Technology"),"."),i.a.createElement("h3",null,"Research"),i.a.createElement(m,null))};function d(e){return i.a.createElement("p",null,i.a.createElement(r.b,{className:"link",to:e.href},i.a.createElement(h.a,{variant:"outlined",href:e.href},i.a.createElement("em",null,e.children))))}var p=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement(d,{href:"/machine-unlearning"},"Data Deletion in Machine Learning"),i.a.createElement(d,{href:"/risk-aware-reinforcement-learning"},"Risk-Aware Reinforcement Learning"),i.a.createElement(d,{href:"/how-differential-privacy-fits-into-industry"},"Where Differential Privacy (Could) Fit Into Industry"),i.a.createElement(d,{href:"/differentially-private-deep-learning"},"A Practitioner","'","s Guide to Differentially Private Deep Learning"))};function g(e){return i.a.createElement("p",null,i.a.createElement(h.a,{variant:"outlined",href:e.href},i.a.createElement("em",null,e.children)))}var f=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement(g,{href:"https://law.stanford.edu/wp-content/uploads/2019/01/Bellovin_20190129.pdf"},"Privacy and Synthetic Datasets"),i.a.createElement(g,{href:"https://cset.georgetown.edu/wp-content/uploads/Keeping-Top-AI-Talent-in-the-United-States.pdf"},"Keeping Top AI Talent in the United States"),i.a.createElement(g,{href:"http://web.stanford.edu/class/psych209/Readings/LakeEtAlBBS.pdf"},"Building Machines That Learn and Think Like People"),i.a.createElement(g,{href:"https://arxiv.org/abs/1911.09421"},"The Linear Algebra Mapping Problem"),i.a.createElement(g,{href:"https://arxiv.org/abs/1905.02175"},"Adversarial Examples Are Not Bugs, They Are Features"),i.a.createElement(g,{href:"https://arxiv.org/abs/2003.03384"},"AutoML-Zero: Evolving Machine Learning Algorithms From Scratch"))};var y=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("p",null,i.a.createElement("img",{src:"./normalizing-flows.png",style:{borderRadius:"10px",width:"100%"}})),i.a.createElement("p",null,i.a.createElement("img",{src:"./hoover.gif",style:{borderRadius:"10px",width:"100%"}})))},w=(a(14),a(1));var b=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("h2",null,"Deleting Data from Machine Learning Models"),i.a.createElement("p",null,"Here","'","s an interesting problem: let","'","s imagine your data was used to train some machine learning model. Now, you want to request that your data be ",i.a.createElement("em",null,"unlearned")," from the model. Roughly speaking, the model is updated so that its parameters and outputs have no knowledge of your data anymore."),i.a.createElement("p",null,"For ",i.a.createElement(w.InlineMath,{math:"k"}),"-nearest neighbors, this problem is trivial - simply remove the point from the dataset. For something more complex like a neural network, it","'","s not immediately clear what you would do. Is there some interesting middle-ground?"),i.a.createElement("p",null,"First, let","'","s define the problem. Consider the two following scenarios:"),i.a.createElement("ul",null,i.a.createElement("li",null,i.a.createElement("em",null,"Case A (Real): We train the model on the full dataset containing ",i.a.createElement(w.InlineMath,{math:"x"}),", we remove ",i.a.createElement(w.InlineMath,{math:"x"})," from the model parameters, and then we publish the model to the public.")),i.a.createElement("li",null,i.a.createElement("em",null,"Case B (Imaginary): The point ",i.a.createElement(w.InlineMath,{math:"x"})," was never in the dataset, we train the model on the dataset (which doesn","'","t contain ",i.a.createElement(w.InlineMath,{math:"x"}),"), and then we publish the model to the public."))),i.a.createElement("p",null,"Here","'",'s what it will mean to be able to "unlearn": if we can find a procedure for Case A which yields an indistinguishable outcome to Case B, then we will have achieved our goal. Meaning, if we can train and then delete, and the outcome of this is indistinguishable from the case where the point was never in the dataset at all, that would be an effective unlearning algorithm.'),i.a.createElement("p",null,"Believe it or not, this is possible in certain cases! For the purposes of this post, I will detail the ",i.a.createElement("u",null,i.a.createElement("a",{href:"https://arxiv.org/abs/2007.02923"},"descent-to-delete"))," approach by Neel et al. To achieve this, we are going to tackle the case of a convex parametric model, e.g., logistic regression with binary cross entropy loss and ",i.a.createElement(w.InlineMath,{math:"\\ell_2"})," regularization."),i.a.createElement("p",null,"To be concrete, let","'","s say our loss function is:"),i.a.createElement(w.BlockMath,{math:"\\ell(\\theta) = - \\frac{1}{n} \\left( \\sum_{i = 1}^{n} y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right) + \\lambda ||\\theta||_2"}),i.a.createElement("p",null,"This loss function is ",i.a.createElement(w.InlineMath,{math:"m"}),"-strongly convex and ",i.a.createElement(w.InlineMath,{math:"M"}),"-smooth, where ",i.a.createElement(w.InlineMath,{math:"m = \\lambda"})," and ",i.a.createElement(w.InlineMath,{math:"M = 4 - \\lambda"}),"."),i.a.createElement("p",null,"Now, the great part about working in this setting is that we have provable convergence guarantees. That is, as long as we know how far we are at most from the global optimum, if we run (projected) gradient descent for some number of steps, we know we will be at most some distance away. To formalize this:"),i.a.createElement("em",null,"Let ",i.a.createElement(w.InlineMath,{math:"\\ell(\\theta)"})," be ",i.a.createElement(w.InlineMath,{math:"m"}),"-strongly convex and M-smooth, and let ",i.a.createElement(w.InlineMath,{math:"\\theta^* = argmin_{\\theta \\in \\Theta} \\ell(\\theta)"}),". We have that after ",i.a.createElement(w.InlineMath,{math:"T"})," steps of gradient descent with step size ",i.a.createElement(w.InlineMath,{math:"\\eta = \\frac{2}{m + M}"}),":"),i.a.createElement(w.BlockMath,{math:"||\\theta_T - \\theta^*||_2 \\leq \\left( \\frac{M - m}{M + m} \\right)^T || \\theta_0 - \\theta^*||_2"}),i.a.createElement("p",null,"Now I","'","ll introduce the algorithm."),i.a.createElement("br",null),i.a.createElement("p",null,"We begin with Case A, where we perform gradient descent on the full dataset for ",i.a.createElement(w.InlineMath,{math:"t"})," steps until ",i.a.createElement(w.InlineMath,{math:"\\theta_0"})," becomes ",i.a.createElement(w.InlineMath,{math:"\\theta_t"}),". The dotted line represents how far away ",i.a.createElement(w.InlineMath,{math:"\\theta_t"})," can possibly be from ",i.a.createElement(w.InlineMath,{math:"\\theta^D"})," due to our convergence guarantee."),i.a.createElement("center",{style:{"background-color":"white",padding:"20px","border-radius":"20px"}},i.a.createElement("img",{src:"../machine-unlearning/image2.svg",width:"50%"})),i.a.createElement("br",null),i.a.createElement("p",null,"Now, let","'","s say that at this point in training, we receive a deletion request for some point ",i.a.createElement(w.InlineMath,{math:"x"}),". To handle this, we","'","ll first need to establish the notion of ",i.a.createElement("em",null,"sensitivity"),". If we have some global optimum, then the ",i.a.createElement("em",null,"sensitivity")," is the furthest away the global minimum can move due to the removal of a single point. When we remove ",i.a.createElement(w.InlineMath,{math:"x"}),", we know that the resulting global minimum ",i.a.createElement(w.InlineMath,{math:"\\theta^{D \\setminus x}"})," can","'","t be ",i.a.createElement("em",null,"too")," far away."),i.a.createElement("center",{style:{"background-color":"white",padding:"20px","border-radius":"20px"}},i.a.createElement("img",{src:"../machine-unlearning/image1.svg",width:"50%"})),i.a.createElement("br",null),i.a.createElement("p",null,"Given this, we know how far away ",i.a.createElement(w.InlineMath,{math:"\\theta_t"})," can be from ",i.a.createElement(w.InlineMath,{math:"\\theta^D"})," and how far ",i.a.createElement(w.InlineMath,{math:"\\theta^D"})," can be from ",i.a.createElement(w.InlineMath,{math:"\\theta^{D \\setminus x}"}),". Therefore, we know how far ",i.a.createElement(w.InlineMath,{math:"\\theta_t"})," could possibly be from ",i.a.createElement(w.InlineMath,{math:"\\theta^{D \\setminus x}"}),". Given this information, we can again apply the convergence guarantee and perform gradient descent for some required number of steps in the direction of ",i.a.createElement(w.InlineMath,{math:"\\theta^{D \\setminus x}"})," until we know we","'","re some distance away, resulting in ",i.a.createElement(w.InlineMath,{math:"\\theta_T"}),". This finishes Case A, where we","'","ve gone from an initial point ",i.a.createElement(w.InlineMath,{math:"\\theta_0"})," and gotten close to ",i.a.createElement(w.InlineMath,{math:"\\theta^{D \\setminus x}"})," without knowing ",i.a.createElement(w.InlineMath,{math:"x"})," beforehand."),i.a.createElement("center",{style:{"background-color":"white",padding:"20px","border-radius":"20px"}},i.a.createElement("img",{src:"../machine-unlearning/image3.svg",width:"50%"})),i.a.createElement("br",null),i.a.createElement("p",null,"Now we consider alternative reality, Case B. That is, we start from our initial point and train regularly but ",i.a.createElement(w.InlineMath,{math:"x"})," was never in the dataset. Given our convergence guarantee, again we can know after some number of steps that we are at least within some distance of the optimum."),i.a.createElement("center",{style:{"background-color":"white",padding:"20px","border-radius":"20px"}},i.a.createElement("img",{src:"../machine-unlearning/image4.svg",width:"50%"})),i.a.createElement("br",null),i.a.createElement("p",null,"Now given that we can guarantee a certain distance from ",i.a.createElement(w.InlineMath,{math:"\\theta^{D \\setminus x}"})," in either case, we can guarantee that ",i.a.createElement(w.InlineMath,{math:"\\theta_T"})," and ",i.a.createElement(w.InlineMath,{math:"\\theta"})," are within some distance of one another."),i.a.createElement("center",{style:{"background-color":"white",padding:"20px","border-radius":"20px"}},i.a.createElement("img",{src:"../machine-unlearning/image5.svg",width:"50%"})),i.a.createElement("br",null),i.a.createElement("p",null,"Finally, in either case, we publish the models according to the same publishing scheme, namely an injection of Gaussian noise to the model parameters scaled to how far ",i.a.createElement(w.InlineMath,{math:"\\theta_T"})," and ",i.a.createElement(w.InlineMath,{math:"\\theta"}),' could possibly be from one another. All of this entails that both outcomes are statistically indistinguishable from one another, in the sense that the probability distributions over both models are "approximately identical".'),i.a.createElement("center",{style:{"background-color":"white",padding:"20px","border-radius":"20px"}},i.a.createElement("img",{src:"../machine-unlearning/image6.svg",width:"50%"})),i.a.createElement("br",null),i.a.createElement("h3",null,"Conclusion"),i.a.createElement("p",null,"Hopefully this was a useful introduction into the problem of machine unlearning and how it can be addressed. For further reading, make sure to check out the blog post detailing ",i.a.createElement("u",null,i.a.createElement("a",{href:"http://www.cleverhans.io/2020/07/20/unlearning.html"},"SISA")),", an alternative approach to machine unlearning proposed by Papernot et al."))};var E=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("h2",null,"A Practitioner","'","s Guide to Differentially Private Deep Learning"),i.a.createElement("p",null,"In this post we tackle the topic of privacy-preserving deep learning. This commentary will be less so concerned with proof, and moreso geared towards convincing a deep learning practitioner what privacy should mean, why it","'","s important, and how it can be achieved."),i.a.createElement("h3",null,"Differential Privacy"),i.a.createElement("p",null,"Before talking about anything else, we need to define what privacy is. Privacy is a high-level English term, and there are many ideas this term ",i.a.createElement("em",null,"could")," refer to. Naturally, some definitions are more useful than others."),i.a.createElement("p",null,"One such definition is ",i.a.createElement("em",null,"differential privacy"),". Differential privacy is concerned with ",i.a.createElement("em",null,"algorithms"),", functions which map datasets to outputs, e.g., linear regression mapping a dataset to its coefficients ",i.a.createElement(w.InlineMath,{math:"w"})," and ",i.a.createElement(w.InlineMath,{math:"b"}),"."),i.a.createElement("p",null,'Such an algorithm would "preserve privacy" under the notion of differential privacy if it were to behave (approximately) the same regardless of whether you removed any individual point from the dataset. If you could achieve this property, then you ',i.a.createElement("em",null,"should")," be convinced that this algorithm is privacy-preserving."),i.a.createElement("p",null,"Why? Well, let","'","s consider how you would feel if one of these points actually corresponded to you. By the definition put forth, you wouldn","'","t have grounds to care whether your data is given to the algorithm - the outcome will be the same regardless. In other words, ",i.a.createElement("em",null,"you should feel like this algorithm preserves your privacy because its outputs look the same whether or not your data is given to it"),". This is the core idea."),i.a.createElement("p",null,"Formally, we can express this notion via the following",i.a.createElement("sup",null,i.a.createElement("a",{href:"https://stephentu.github.io/writeups/6885-lec20-b.pdf"},"1")),":"),i.a.createElement("p",null,i.a.createElement("em",null,"Let ",i.a.createElement(w.InlineMath,{math:"A : \\mathcal{D} \\rightarrow \\mathcal{Y}"})," be a randomized algorithm. We call ",i.a.createElement(w.InlineMath,{math:"A"}),' "',i.a.createElement(w.InlineMath,{math:"\\varepsilon"}),'-differentially private" if for all ',i.a.createElement(w.InlineMath,{math:"D_1, D_2 \\in \\mathcal{D}"})," differing in exactly one entry, and for all outputs ",i.a.createElement(w.InlineMath,{math:"y \\in \\mathcal{Y}"}),", we have that:",i.a.createElement(w.BlockMath,{math:"e^{-\\varepsilon} \\leq \\frac{\\Pr[\\mathcal{A(D_1) = y}]}{\\Pr[\\mathcal{A(D_2) = y}]} \\leq e^\\varepsilon"}))),i.a.createElement("p",null,"Upon inspection, you","'","ll notice that this is saying more or less what we established earlier. Namely, the probability of a particular outcome occuring is about the same (the ratio between the two outcomes is about equal to 1) whether or not you include any particular individual in the dataset."),i.a.createElement("h3",null,"Deep Learning"),i.a.createElement("p",null,"It goes without saying that deep learning has become an extremely popular form of statistical analysis. And conveniently, the algorithms of concern in the context of deep learning align perfect with the interface prescribed by differential privacy, namely in mapping provided datasets to some output space."),i.a.createElement("p",null,"One of the most pervasive approaches to deep learning is through the process of stochastic gradient descent. When conducting stochastic gradient descent, we iteratively update the parameters of a model by repeatedly sampling data and taking small steps over the parameters in the direction which minimizes our loss function. In other words, we repeatedly follow something like the following:"),i.a.createElement(w.BlockMath,{math:"\\{ x^{(1)}, x^{(1)}, \\ldots x^{(b)} \\} \\sim sample(X, b)"}),i.a.createElement(w.BlockMath,{math:"\\ell(\\theta) = \\frac{1}{b} \\sum_i \\ell(x^{(i)} ; \\theta)"}),i.a.createElement(w.BlockMath,{math:"\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta \\ell(\\theta)"}),i.a.createElement("p",null,"This begs the question: how do we do this to maintain differential privacy?"),i.a.createElement("h3",null,"Differentially Private Stochastic Gradient Descent"),i.a.createElement("p",null,i.a.createElement("a",{href:"https://arxiv.org/abs/1607.00133"},"Abadi et al.")," detail the differentially private stochastic gradient descent (DP-SGD) algorithm to make traditional SGD yield a differential privacy guarantee. To describe it, we need to introduce a number of augmentations."),i.a.createElement("p",null,"First, we have to specify our method for sampling. In the context of non-private deep learning, sampling is often achieved by shuffling the dataset and running through partitions of size ",i.a.createElement(w.InlineMath,{math:"b"})," such that each example is viewed by the model exactly once per epoch. Although in the context of DP-SGD, we must opt for either Poisson",i.a.createElement("sup",null,"2")," or uniform",i.a.createElement("sup",null,"3")," subsampling if we want to retain an actual differential privacy guarantee."),i.a.createElement("p",null,"Second, we need to augment the gradient calculation. In particular, we need to introduce a clipping parameter ",i.a.createElement(w.InlineMath,{math:"C"})," (an upper bound on the ",i.a.createElement(w.InlineMath,{math:"\\ell_2"}),"-norm of each per-example gradient) as well as the noise multiplier ",i.a.createElement(w.InlineMath,{math:"\\sigma"})," (which scales the variance of the Gaussian noise applied to each gradient update after clipping). All of this together, we execute the following augmented training loop:"),i.a.createElement(w.BlockMath,{math:"\\{ x^{(1)}, x^{(1)}, \\ldots x^{(b)} \\} \\sim sample(X, b)"}),i.a.createElement(w.BlockMath,{math:"g^{(i)} \\leftarrow \\nabla_{\\theta} \\ell(x^{(i)} ; \\theta)"}),i.a.createElement(w.BlockMath,{math:"\\bar{g}^{(i)} \\leftarrow g^{(i)} / \\max\\{ 1, ||g^{(i)}||_2 / C\\}"}),i.a.createElement(w.BlockMath,{math:"\\tilde{g} \\leftarrow \\frac{1}{b} (\\sum_i \\bar{g}^{(i)} + \\sigma \\cdot C \\cdot \\mathcal{N}(0, I))"}),i.a.createElement(w.BlockMath,{math:"\\theta \\leftarrow \\theta - \\eta \\tilde{g}"}),i.a.createElement("p",null,"In order to calculate the privacy loss corresponding to ",i.a.createElement(w.InlineMath,{math:"t"})," executions of the above update rule, Abadi et al. also detail the ",i.a.createElement("em",null,"moments accountant"),", a specialized analysis capable of reporting the privacy loss over time. A full deep dive into tools used in the moments accountant is beyond the scope of this post, but it can be understood as simply a black box which takes in your training loop parameters (",i.a.createElement(w.InlineMath,{math:"C"}),", ",i.a.createElement(w.InlineMath,{math:"\\sigma"}),", ",i.a.createElement(w.InlineMath,{math:"t"}),", ",i.a.createElement(w.InlineMath,{math:"b"}),") and gives you ",i.a.createElement(w.InlineMath,{math:"\\varepsilon"}),". If you","'","re interested in learning more, there","'","s a corresponding implementation in Tensorflow Privacy."),i.a.createElement("h3",null,"Private Aggregation of Teacher Ensembles"),i.a.createElement("p",null,"Of course, DP-SGD is only one of several ways to train (or get the predictions) of a machine learning model while preserving privacy."),i.a.createElement("p",null,"Private Aggregation of Teacher Ensembles (PATE) is an alternative approach, better suited in certain contexst. The key idea is to, rather than train a single model in a privacy-preserving manner, train a set of weaker, non-private models on partitions of the dataset and perform a noisy aggregation of their predictions to preserve privacy."),i.a.createElement("p",null,"Overall this method has been shown to be quite effective, at the expense of some additional assumptions about the training procedure. In many contexts an ensemble will perform quite well, and so noise injection is best applied at the level of the prediction rather than the level of the internal model parameters. If your model has a million parameters, who knows what noise injection could do to its learned criteria!"),i.a.createElement("h3",null,"Conlusion"),i.a.createElement("p",null,"Hopefully this was a useful tutorial outlining differential privacy and its applications to deep learning in plain English. If you have any questions or have caught any errors, feel free to reach out!"))};var v=function(){return i.a.createElement("div",null,i.a.createElement("h2",null,"How Differential Privacy (Could) Fit Into Industry"),i.a.createElement("p",null,"In the context of differential privacy, there","'","s typically some data curator (e.g. some silicon valley tech giant) and the outside world. Supposedly the curator has an incentive to release some data analysis result, but in such a way where the privacy leakage associated with this analysis is trackable."),i.a.createElement("p",null,"Although, there are several practical issues with this. One which is common is this issue of an ",i.a.createElement("em",null,"infinite horizon"),". That is, say this silicon valley tech giant wants to adhere to a strict privacy budget for the rest of eternity. When they want to release the result of an analysis, what epsilon should they choose? 1? 0.1? 0.0001? It\u2019s unclear, especially if their goal is to stick around for eternity, and we assume that the privacy leakage associated with a given analysis is permanant."),i.a.createElement("p",null,"What will happen? Well, once they\u2019ve inevitably creeped up on their limit, should we expect them to seriously consider halting the release of further results forever? No - more than likely, they\u2019ll just raise the limit. And inevitably they\u2019ll do it again. This is to say that, in the context of entities which have no foreseeable horizon, the apparent practicality of differential privacy is of concern because the privacy expenditure is a monotonically increasing value over time."),i.a.createElement("p",null,"This is not a problem I have a general solution to. I\u2019m a big fan of differentially private synthetic datasets, and in certain contexts they can help in this regard. Although, not every undertaking can be easily framed as a synthetic data problem, especially if new relevant data comes in consistently."),i.a.createElement("p",null,"Although, the core point here I\u2019d like to make is that ",i.a.createElement("em",null,"the continual public release of results to analyses may not be the most interesting or useful context to evaluate the utility of differential privacy within"),"."),i.a.createElement("p",null,"Instead, consider the case where an engineer at the aforementioned silicon valley tech giant accidentally leaves their laptop in the car and it gets stolen, and say they were doing some work concerning sensitive data. Can you begin to quantify the amount of damage done to the individuals included in the data they were working with? Not by default, but naturally if the results the engineer was working with were computed with differential privacy in mind, then you could actually start to get some form of a guarantee."),i.a.createElement("p",null,"So, the slight distinction I\u2019m making here is that maybe the utility of differential privacy is not as pronounced in contexts where the forefront goal is information release. Maybe a more useful context for differential privacy is actually behind the walls of your organization."),i.a.createElement("p",null,"That is, the incorporation of differential privacy might be best served as a means for protection against the worst case scenario, where a data leakage happens against your will. Now the conversation shifts from saying \u201csilicon valley tech giant, use differential privacy so that your public analyses don\u2019t reveal too much about your users\u201d, and it becomes \u201chave your employees speak through the lens of differential privacy, so we know how much damage has been done in the worst case where information is leaked.\u201d"),i.a.createElement("p",null,"This reformulation of the problem setting, in a bit of a roundabout matter, highlights the utility of differential privacy by dampening issues concerning infinite horizons, stemming from the inherent nature of data leakages. Namely, they are ",i.a.createElement("em",null,"sparse")," and ",i.a.createElement("em",null,"unintended"),"."),i.a.createElement("p",null,"Given that data leakages are canonically sparse, this allows you to talk about a global privacy budget per individual which might actually be useful. That is, you could actually get away with something like an epsilon of 1.0 per user over a very long timespan if data release occurs every ten years, not every day."),i.a.createElement("p",null,"In addition, it doesn\u2019t make sense to complain about the limitations of differential privacy with respect to its monotonically increasing nature if data release is unintended by definition - if it\u2019s going to happen regardless, you don\u2019t have to worry as much about the number of releases you intend to perform forever onwards because that\u2019s not a variable you can control in the first place."),i.a.createElement("p",null,"There are just my thoughts in isolation, and this has been said before by others. But hopefully it sparks additional discussion on the topic, on where differential privacy will make the most sense to be deployed in the real world in years to come."))};var k=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("h2",null,"Risk-Aware Reinforcement Learning"),i.a.createElement("p",null,"In this post, we will investigate the notion of risk in the context of reinforcement learning."),i.a.createElement("h3",null,"Actor-Critic"),i.a.createElement("p",null,"Actor critic methods, in my opinion, are often described in strangely confusing ways despite not being a particularly complex topic. Here we","'","ll offer a brief introduction."),i.a.createElement("p",null,"First we have a notion of a critic ",i.a.createElement(w.InlineMath,{math:"\\hat{Q}: \\mathcal{S} \\times \\mathcal{A} \\rightarrow \\mathbb{R}"})," which takes in a state ",i.a.createElement(w.InlineMath,{math:"s"})," and an action ",i.a.createElement(w.InlineMath,{math:"a"})," and produces an estimate ",i.a.createElement(w.InlineMath,{math:"\\hat{Q}(s, a)"})," of the expected long-term reward of taking action ",i.a.createElement(w.InlineMath,{math:"a"})," in state ",i.a.createElement(w.InlineMath,{math:"s"}),", and following the policy afterwards. To learn a good estimate of this function, we compare this estimate against a target ",i.a.createElement(w.InlineMath,{math:"Q(s, a) = r + \\gamma \\sum_{s'} p(s' | s, a) \\hat{Q}(s', a')"})," during training, which partially incorporates ground-truth information in the form of an observed reward combined with a bootstrapped estimate. We then simply take a gradient step in the direction minimizing the difference between our computed estimate and our target."),i.a.createElement(w.BlockMath,{math:"\\theta_Q \\leftarrow \\theta_Q - \\eta \\nabla_{\\theta_Q} (\\hat{Q}(s, a) - Q(s, a))^2"}),i.a.createElement("p",null,"Second we introduce a notion of an actor ",i.a.createElement(w.InlineMath,{math:"A: \\mathcal{S} \\rightarrow \\mathcal{A}"})," which simply takes in a state ",i.a.createElement(w.InlineMath,{math:"s"})," and outputs an action ",i.a.createElement(w.InlineMath,{math:"a"}),". To quantify the quality of this predicted action, we pass ",i.a.createElement(w.InlineMath,{math:"s"})," and ",i.a.createElement(w.InlineMath,{math:"a"})," into the critic, which then outputs the expected long-term reward of taking ",i.a.createElement(w.InlineMath,{math:"a"})," in ",i.a.createElement(w.InlineMath,{math:"s"}),". Assuming this estimate is decent, we would then want to update the actor in such a manner so as to maximize this value, so we take a gradient step in the direction achieving this."),i.a.createElement(w.BlockMath,{math:"\\theta_A \\leftarrow \\theta_A + \\eta \\nabla_{\\theta_A} \\hat{Q}(s, A(s))"}),i.a.createElement("p",null,"After alternating between training the actor and training the critic while exploring the environment, we should eventually converge on a good value function and a good actor characterizing the policy of the agent."),i.a.createElement("h3",null,"What is Risk?"),i.a.createElement("p",null,"Now, imagine that our critic didn","'","t just estimate the expected long-term reward, but it estimated the entire ",i.a.createElement("em",null,"distribution")," of long term rewards. Maybe we could assume that this distribution is a Gaussian, and predict its mean and variance. Assuming we could do that, then how might we define risk?"),i.a.createElement("p",null,"Well, one way you could think about risk is that it","'","s ",i.a.createElement("em",null," the degree to which you are concerned about worst-case outcomes"),". If you are risk-averse, that means you ",i.a.createElement("em",null,"only")," care about worst case outcomes. If you are risk-willing, then you might only care about average-case outcomes."),i.a.createElement("p",null,"A way to formalize this notion is through ",i.a.createElement("em",null,"conditional value at risk (CVaR)"),". Given a distribution, it is defined as the expectation of the distribution up to the ",i.a.createElement(w.InlineMath,{math:"\\alpha"}),"-th percentile. If ",i.a.createElement(w.InlineMath,{math:"\\alpha \\approx 0"}),", then you essentially only care about the worst case. If ",i.a.createElement(w.InlineMath,{math:"\\alpha = 1"}),", then you only care about expected case (which would be regular actor-critic!) Anything in between is simply some domain-specific tradeoff."),i.a.createElement("p",null,"This is the idea followed in the paper ",i.a.createElement("em",null,i.a.createElement("a",{href:"https://arxiv.org/abs/1911.03618"},"Worst Case Policy Gradient"))," by Tang et al., and the basis for this post."),i.a.createElement("h3",null,"Training the Critic"),i.a.createElement("p",null,"Getting the estimated means and variances from your model is fairly straightforward - just feedforward your critic model! Give it a state and an action and it will spit out the estimated mean and variance."),i.a.createElement(w.BlockMath,{math:"\\{ \\hat{Q}(s, a), \\hat{\\Upsilon}(s, a) \\} = critic(s, a)"}),i.a.createElement("p",null,"Now how will we attain good estimates for ",i.a.createElement(w.InlineMath,{math:"\\hat{Q}(s, a)"})," and ",i.a.createElement(w.InlineMath,{math:"\\hat{\\Upsilon}(s, a)"}),"? By the same idea of computing targets given observed reward information. Fist, the mean is actually quite easy because it has precisely the same semantic interpretation of the regular Q-value, hence going unchanged."),i.a.createElement(w.BlockMath,{math:"Q(s, a) = r + \\gamma \\sum_{s'} p(s' | s, a) \\hat{Q}(s', a')"}),i.a.createElement("p",null,"Now we just need to sort out what the proper variance target should look like. By simply expanding the definition of variance, you should end up with an expression resembling the following."),i.a.createElement(w.BlockMath,{math:"\\Upsilon(s, a) \\leftarrow r^2 + 2 \\gamma r \\sum_{s} p(s' | s, a) \\hat{Q}(s', a')"}),i.a.createElement(w.BlockMath,{math:"+ \\gamma^2 \\sum_{s'} p(s' | s, a) \\hat{\\Upsilon}(s', a') + \\gamma^2 \\sum_{s'} p(s' | s, a) \\hat{Q}(s', a')^2 - \\hat{Q}(s, a)^2"}),i.a.createElement("p",null,"Now we have our ",i.a.createElement("em",null,"estimates"),", namely ",i.a.createElement(w.InlineMath,{math:"\\hat{Q}(s, a)"})," and ",i.a.createElement(w.InlineMath,{math:"\\hat{\\Upsilon}(s, a)"}),", as well as our ",i.a.createElement("em",null,"targets"),", namely ",i.a.createElement(w.InlineMath,{math:"Q(s, a)"})," and ",i.a.createElement(w.InlineMath,{math:"\\Upsilon(s, a)"}),"."),i.a.createElement("p",null,"Now we have to construct a loss function which will quantify how good our estimates are. Why not define our loss function as some statistical distance metric between the Gaussian distributions characterized by our estimate and target? It turns out, the Wasserstein distance between the two Gaussians can be characterized by the following expression."),i.a.createElement(w.BlockMath,{math:"\\ell(\\theta) = (\\hat{Q}(s, a) - Q(s, a))^2"}),i.a.createElement(w.BlockMath,{math:"+ \\hat{\\Upsilon}(s, a) + \\Upsilon(s, a) - 2\\sqrt{\\hat{\\Upsilon}(s, a) \\Upsilon(s, a)}"}),i.a.createElement("p",null,"This expression should satisfy our intuition - the loss is zero when ",i.a.createElement(w.InlineMath,{math:"\\hat{Q}(s, a) = Q(s, a)"})," and ",i.a.createElement(w.InlineMath,{math:"\\hat{\\Upsilon}(s, a) = \\Upsilon(s, a)"}),", and positive otherwise."),i.a.createElement("h3",null,"Training the Actor"),i.a.createElement("p",null,"Now how should we train our actor? This part is easy assuming we have a trained critic. Just as before, we pass in a state ",i.a.createElement(w.InlineMath,{math:"s"})," to our actor which will give us an action ",i.a.createElement(w.InlineMath,{math:"a"}),". This action is then passed into the critic, which yields a mean ",i.a.createElement(w.InlineMath,{math:"\\hat{Q}(s, a)"})," and a variance ",i.a.createElement(w.InlineMath,{math:"\\hat{\\Upsilon}(s, a)"}),". Given this mean and variance, we can directly calculate the ",i.a.createElement("emph",null,"CVaR")," metric as the following where ",i.a.createElement(w.InlineMath,{math:"\\phi(\\alpha)"})," is the PDF of the Gaussian distribution evaluated at ",i.a.createElement(w.InlineMath,{math:"\\alpha"})," and ",i.a.createElement(w.InlineMath,{math:"\\Phi(\\alpha)"})," is the CDF."),i.a.createElement(w.BlockMath,{math:"\\Gamma(s, a, \\alpha) = \\hat{Q}(s, a) - \\frac{\\phi(\\alpha)}{\\Phi(\\alpha)}\\sqrt{\\hat{\\Upsilon}(s, a)}"}),i.a.createElement("p",null,"This is the scalar we want! Now, the actor just takes a gradient step in the direction ",i.a.createElement("em",null,"maximizing")," this value. Super simple!"),i.a.createElement("h3",null,"Conclusion"),i.a.createElement("p",null,"Hopefully this acted as a simple introduction to risk in the context of reinforcement learning. If you have any questions, feel free to shoot them my way!"))},I=a(20);var M=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("h2",null,"Deaths of Despair"),i.a.createElement("p",null,i.a.createElement("em",null,"Ecclesiastes 1:9. What has been will be again, what has been done will be done again; there is nothing new under the sun.")),i.a.createElement("p",null,"I believe this is true in one sense, but false in another. Have these things been echoed in other forms in the past? Absolutely. But are these manifestations becoming increasingly more potent? I would argue so."),i.a.createElement("p",null,"In the past, you at least had some degree of separation between you and the elite. You can realize this in a few ways, but the way I think the most clearly about is the following. That is, on average, the amount of time these individuals occupy your direct attention, with some implicit weight on subconscious attention."),i.a.createElement("p",null,"Let\u2019s take the median American who makes around $33,706 a year (2018). Now, convince yourself there exists some probability, no matter how small, that such a person exhibits a chance of breaking down upon seeing such a photo after a long and hard day at work."),i.a.createElement("p",null,"How many times a day do you think that coin is flipped? There are 350 million americans. Wouldn\u2019t you like to be him? He looks well rested, and if he were to go up to any of his million fans, he would be undoubtedly praised like a living god."),i.a.createElement("h3",null,"Wealth Inequality"),i.a.createElement("p",null,"I see Amazon as a useful analog. If you had to distill America","'","s problem, it could be physically manifested as Amazon","'","s structure. Essentially, we have a clear balkanization and class structure. Which is, we have the elite which make decisions and live way more well off than necessary, the engineers, the lower class who are treated unreasonably poorly, and the hyper-elite Jeff Bezos money who is more valuable than is really coprehensible."),i.a.createElement("p",null,"At the time of writing this, Jeff Bezos is worth approximately 180 billion dollars. To conceptualize this, consider a billionaire. To become a billionaire, you would have had to have had a 4 million dollar salary every year throughout all of American history, which is an absolutely ridiculous salary to have persisted through the civil war, the invention of the cotton gin, throught the civil rights movement, until now. That is poverty in relation to Jeff Bezos."),i.a.createElement("p",null,"Now, the problem per say clearly isn","'","t that automation or wealth inequality is new in some sense, this is clearly false. But I would argue that a problem which rapidly exacerbates is indistinguishable from a new problem, and that this principle applies in this context. Of course, every time a new technology comes around it ripples throughout the economy. But the problem now is that the proportions of the population our innovations are having are growing, and the skills they undermine require more and more prior investment. Of course, when the cotton gin came around people surely lost their jobs, but finding other blue collar work was an alternative and learning the upkeep a cotton gin, which required more skill than picking the cotton itself, took an investment on the order of days. Now, we","'","re talking about technology which could potentially undermine manual labor all together, and using methods which require so much more skill, at an unprecedented speed."),i.a.createElement("p",null,"The key difference is the following key metric. What proportion of outsourced workers were able to actually contribute or play a part in the technology which outsourced them? With the cotton gin, I would argue that that number was modestly high. That is, the skills you had to be a picker of cotton weren","'","t too far off from maintaining a cotton gin or thinking of new ideas to improve it, it was a mechanical contraption after all. Of course not everyone would exhibit that effort and might simply switch to another industry, but the possibility was there. What proportion of truck drivers outsourced will be able to contribute or play a part in self-driving car technology? Literally zero percent."),i.a.createElement("p",null,"So lets say you think well get past the self driving truck issue, which id agree we probably will at some cost. Well, again, this is getting worse. Whats the next large scale technological innovation to be had? Almost surey the end of menial white collar work requiring basic linguistic ability and reasoning skills, aka lawyers, accountants and the like. What are we going to tell 40 year old men with kids and a mortgage? Especially when the maintenance of this software requires a team of three engineers? Im sorry but theres no jobs available in this context - midway through your career you might just need to learn how to be a pharmacologist. Its almost in some sense like our efficiency and problem solving ability has become too low of a barrier to entry for our own good."),i.a.createElement("p",null,"Again, my argument is not that self driving cars will be the end of civilization. Its that the implications of technological innovation are getting worse. If you think this round of innovation isn","'","t sufficient, wait 100 years. What will we be outsourcing then?"),i.a.createElement("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/G1UpFHsbOf0?start=1745",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}),i.a.createElement("h3",null,"Social Media"),i.a.createElement("h4",null,"Twitch"),i.a.createElement("p",null,"I can","'","t say my response to such incidents better than it was said by /u/Thopterthallid in ",i.a.createElement("a",{href:"https://www.reddit.com/r/AskReddit/comments/ca0gm6/people_who_ordered_belle_delphines_bathwater_why/et5pesf?utm_source=share&utm_medium=web2x"},"this")," comment."),i.a.createElement("p",null,i.a.createElement("details",null,i.a.createElement("summary",null,i.a.createElement("i",null,'I want to try and break "Gamer girl water" down for people...')),i.a.createElement("i",null,'...coming from someone who had a dark time in my life where I might have been tempted to buy some "gamer girl bath water". It',"'",'s easy to say "Oh she',"'",'s just tricking idiots out of their money" but it',"'","s a little more complicated than that.",i.a.createElement("br",null),i.a.createElement("br",null),i.a.createElement("b",null,"When you","'","re approaching your mid to late 20s and still haven","'","t enjoyed a healthy and intimate relationship, it really does start to fuck with you on a scary level.")," Mental illness, depression, anxiety, and such seem to be a much more prevalent nowadays since it","'",'s so easy to get "quick fix" social interaction through the internet. The internet is amazing, but it doesn',"'","t make you better at actually being a social human being in real life. You get guys who had quick and easy access to a hundred friends on MSN/AIM/Skype/Discord/Telegram grow increasingly dependant on online interactions for their social needs. I can confirm it gets to the point where you just don","'","t even really want real interactions anymore because pornhub handles your libido, twitch gives you someone to listen to, instant messaging gives you people to talk to, etc. The only thing missing is the sexual physical touch of a woman, and there","'","s a part of you that might think that water that","'","s touched your Twitch crush will satisfy that. It won","'","t of course.",i.a.createElement("br",null),i.a.createElement("br",null),i.a.createElement("b",null,"The way that the most popular Youtubers, and Twitch Streamers interact with their audience is that of being a friend, family, or lover.")," How many streamers call their viewers some kind of pet name? Like, the [Streamer name] Family, or the [Streamer name] Army. When your livelihood comes from donations and views, you need to be especially charismatic. The biggest names in online video makers always talk directly to their audience. They look into the camera, they call you their friends and family, they want you to hang out with them at conventions, and they want to hear your comments, they want to read your messages in chat, they offer life advice, they tell you they care about you, they tell you they","'","re thankful for you, they want you to take care of yourself, and often times they","'","ll open up their soul and talk about their lives to you. It","'","s all about charisma and being a good host and it","'","s a great talent to have. For people in the previous point, this can actually be super harmful. You spend enough time in their streams and watching their videos, and you really do start to subconsciously believe that Markiplier, Pewdiepie, and Summit are your friends. Obviously it","'","s not the case, but there was a time in my life where some of my favourite Youtubers were appearing in my dreams and were asking me to hang out, and my brain didn","'","t even question that it was something we just did all the time. I recall a few years ago some kids and their mom showed up to a famous Twitch streamer","'","s address and were confused as to why he felt that was a breach of privacy. They expected to hang out with him, get autographs, play games with him, and all around expect that he","'","d be thrilled to see them. Obviously, this is a huge breach of boundaries, and perfectly sane people just forget that these people don","'","t have a 1:1 friendship with them.",i.a.createElement("br",null),i.a.createElement("br",null),i.a.createElement("b",null,"When you","'","re 25+ and haven","'","t had meaningful relationships with women, either romantic or otherwise, you start to get weird ideas about what women are, especially if you talk to the wrong groups.")," When you get to the point where you","'","ve craved intimate love and never had it for over ten years, you start getting weird ideas. Some men lash out at women and get incel-ish. Some men put women on these pedestals as divine trophies to be won. Some men just assume that women will never like them. But the longer you go without ever knowing love, the easier it is to think of women as being a totally different species.",i.a.createElement("br",null),i.a.createElement("br",null),i.a.createElement("b",null,"When every woman you","'","ve ever known either hates video games or are casual/novice gamers at best, meeting a woman who seems to idolize gaming as much as you do triggers volatile emotions.")," Sometimes it comes in the form of disdain and skepticism, and end up making a toxic environment for women in gaming. If not that, it comes out as excessive idolization. You","'","re at a point in your life where any woman who would even pay attention to you is a dream, and the thought of a girl who would share your favourite hobby with you may as well be the second coming of Christ. You crush on her hard, you buy all her merch, you send her donations so that she","'",'ll start to recognize your name and tell you "thank you" and read your messages. I',"'","m not saying that women shouldn","'","t be allowed to be successful gaming streamers, but I do think that taking advantage of clinically depressed and lonely fans like this is awful.",i.a.createElement("br",null),i.a.createElement("br",null),i.a.createElement("b",null,"This whole, selling bathwater thing to thirsty fans may seem like memes and trolling, but in reality it","'","s just highlighting a very, very sad reality.")," There","'","s guys out there who would buy this in a futile attempt just to feel closer to the one girl that ever paid them any attention. I was dangerously close to being one of those guys at one point and I know just how scary the spiral goes. People on my path would either end up doing things like buying this bathwater or becoming misogynistic incels.",i.a.createElement("br",null),i.a.createElement("br",null),"It all sounds so stupid and pathetic, but it","'","s a very true reality for some unfortunate guys suffering from severe depression.")),i.a.createElement("br",null)),i.a.createElement("h4",null,"Tinder"),i.a.createElement("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/2O-iLk1G_ng?start=3103",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}),i.a.createElement(I.a,{url:"https://instagr.am/p/Bfw2OPinqme/",maxWidth:320,hideCaption:!0}),i.a.createElement(I.a,{url:"https://instagr.am/p/BoPAPVKAnS0/",maxWidth:320,hideCaption:!0}),i.a.createElement("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/PMotykw0SIk?start=1282",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}))};var x=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("h2",null,"Where We Are Now"),i.a.createElement("h3",null,"The Past"),i.a.createElement("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/WYaluOHcATU?start=88",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}),i.a.createElement("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/l6i-gYRAwM0",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}),i.a.createElement("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/NRCWbFFRpnY",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}),i.a.createElement("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/Rm6xL0klXcQ",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}),i.a.createElement("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/iTACH1eVIaA",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}),i.a.createElement("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/ec9P3C1OXqE",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}),i.a.createElement("p",null,i.a.createElement("em",null,"\"He's got a great personality. He's a funny guy, he's very smart, he's a great negotiator. He loves his people, not that I'm surprised by that. I think that we have the start of an amazing deal.\" - Donald Trump")),i.a.createElement("p",null,i.a.createElement("em",null,"\"I've known Jeff for 15 years. Terrific guy. He's a lot of fun to be with. It is even said that he likes beautiful women as much as I do, and many of them are on the younger side.\" - Donald Trump")))};var T=function(){return i.a.createElement(o,null,i.a.createElement(s.a,{exact:!0,path:"/",component:u}),i.a.createElement(s.a,{path:"/about",component:u}),i.a.createElement(s.a,{path:"/research",component:m}),i.a.createElement(s.a,{path:"/writing",component:p}),i.a.createElement(s.a,{path:"/reading",component:f}),i.a.createElement(s.a,{path:"/design",component:y}),i.a.createElement(s.a,{path:"/deaths-of-despair",component:M}),i.a.createElement(s.a,{path:"/where-we-are-now",component:x}),i.a.createElement(s.a,{path:"/how-differential-privacy-fits-into-industry",component:v}),i.a.createElement(s.a,{path:"/differentially-private-deep-learning",component:E}),i.a.createElement(s.a,{path:"/risk-aware-reinforcement-learning",component:k}),i.a.createElement(s.a,{path:"/machine-unlearning",component:b}))},A=a(12);a.n(A).a.render(i.a.createElement(r.a,null,i.a.createElement(T,null)),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})).catch((function(e){console.error(e.message)}))}},[[28,1,2]]]);
//# sourceMappingURL=main.e869edc1.chunk.js.map